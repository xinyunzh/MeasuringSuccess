{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This workbook contains the basic data preparation for coding for overlap analysis from 2016Q1 tp 2018Q2\n",
    "####   -  including financial measurement such as wages, savings, creditscore, debt, incomeHH \n",
    "####   -  as well as FinCap measurement such as latefee, incomeexpenses. autodeposit, emergencyfund, budget, goals\n",
    "####  -  mostly calculated the *most recent input within one year*\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> most recent input within one year.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook Font\n",
    "\n",
    "#https://www.ibm.com/support/knowledgecenter/SSQNUZ_current/com.ibm.icpdata.doc/dsx/markd-jupyter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Leah\\\\Google Drive\\\\Parent Folder\\\\2. Clients\\\\Local\\\\Dallas\\\\Communities Foundation of Texas\\\\Q22018\\\\Data Work\\\\ForOverlapAnalysis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.read_excel(r\"C:\\Users\\Leah\\Google Drive\\Parent Folder\\2. Clients\\Local\\Dallas\\Communities Foundation of Texas\\All Q Merged Q22017\\AllQMerged_Overlap.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlier = pd.read_excel(r\"C:\\Users\\Leah\\Google Drive\\Parent Folder\\2. Clients\\Local\\Dallas\\Communities Foundation of Texas\\All Q Merged Q22017\\AllQMerged_Outliers.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FinCap_LateFee_Merged',\n",
       " 'FinCap_IncomeExpenses_Merged',\n",
       " 'FinCap_AutoDeposit_Merged',\n",
       " 'FinCap_EmergencyFund_Merged',\n",
       " 'FinCap_Budget_Merged',\n",
       " 'FinCap_Goals_Merged',\n",
       " 'Savings_Merged',\n",
       " 'CreditScore_Merged',\n",
       " 'Debt_Merged',\n",
       " 'Wage_Merged',\n",
       " 'Income_Merged',\n",
       " 'AccessEmployment_Merged2',\n",
       " 'AccessFinancialCoach_Merged2',\n",
       " 'AccessIncome_Merged2',\n",
       " 'BundledServices_Merged2',\n",
       " 'Savings_Merged2',\n",
       " 'CreditScore_Merged2',\n",
       " 'Debt_Merged2',\n",
       " 'Wage_Merged2',\n",
       " 'Income_Merged2',\n",
       " 'FinCap_Budget_Merged2',\n",
       " 'FinCap_Goals_Merged2',\n",
       " 'FinCap_EmergencFund_Merged2',\n",
       " 'FinCap_AutoDeposit_Merged2',\n",
       " 'FinCap_IncomeExpenses_Merged2',\n",
       " 'FinCap_LateFee_Merged2',\n",
       " 'Savings_Merged_Y1',\n",
       " 'CreditScore_Merged_Y1',\n",
       " 'Debt_Merged_Y1',\n",
       " 'Wage_Merged_Y1',\n",
       " 'IncomeHH_Merged_Y1',\n",
       " 'FinCap_Budget_MergedYear1',\n",
       " 'Fincap_Goals_MergedYear1',\n",
       " 'FinCap_EmergencyFund_MergedYear1',\n",
       " 'FinCap_AutoDeposit_MergedYear1',\n",
       " 'FinCap_IncomeExpenses_MergedYear1',\n",
       " 'FinCap_LateFee_MergedYear1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df_overlap.columns if 'Merged' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the last 82 columns' dataframe \n",
    "#df_overlap[df_overlap.columns[-82:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AccessEmployment_Merged2', 'AccessFinancialCoach_Merged2',\n",
       "       'AccessIncome_Merged2', 'BundledServices_Merged2', 'CreditScore Both',\n",
       "       'CreditScore_Blank', 'CreditScore_Blank2', 'CreditScore_IsBlank_Y1',\n",
       "       'CreditScore_Merged', 'CreditScore_Merged2', 'CreditScore_Merged_Y1',\n",
       "       'Debt Both', 'Debt_Blank', 'Debt_Blank2', 'Debt_IsBlank_Y1',\n",
       "       'Debt_Merged', 'Debt_Merged2', 'Debt_Merged_Y1',\n",
       "       'FinCap_AutoDeposit_Both', 'FinCap_AutoDeposit_IsBlank',\n",
       "       'FinCap_AutoDeposit_IsBlank2', 'FinCap_AutoDeposit_IsBlankYear1',\n",
       "       'FinCap_AutoDeposit_Merged', 'FinCap_AutoDeposit_Merged2',\n",
       "       'FinCap_AutoDeposit_MergedYear1', 'FinCap_Budget_Both',\n",
       "       'FinCap_Budget_IsBlank', 'FinCap_Budget_IsBlank2',\n",
       "       'FinCap_Budget_IsBlankYear1', 'FinCap_Budget_Merged',\n",
       "       'FinCap_Budget_Merged2', 'FinCap_Budget_MergedYear1',\n",
       "       'FinCap_EmergencFund_Both', 'FinCap_EmergencFund_Isblank2',\n",
       "       'FinCap_EmergencFund_Merged2', 'FinCap_EmergencyFund_IsBlank',\n",
       "       'FinCap_EmergencyFund_IsBlankYear1', 'FinCap_EmergencyFund_Merged',\n",
       "       'FinCap_EmergencyFund_MergedYear1', 'FinCap_Goals_Both',\n",
       "       'FinCap_Goals_IsBlank', 'FinCap_Goals_IsBlank2', 'FinCap_Goals_Merged',\n",
       "       'FinCap_Goals_Merged2', 'FinCap_IncomeExpenses_Both',\n",
       "       'FinCap_IncomeExpenses_IsBlank', 'FinCap_IncomeExpenses_IsBlank2',\n",
       "       'FinCap_IncomeExpenses_IsBlankYear1', 'FinCap_IncomeExpenses_Merged',\n",
       "       'FinCap_IncomeExpenses_Merged2', 'FinCap_IncomeExpenses_MergedYear1',\n",
       "       'FinCap_LateFee_Both', 'FinCap_LateFee_IsBlank',\n",
       "       'FinCap_LateFee_IsBlank2', 'FinCap_LateFee_IsBlankYear1',\n",
       "       'FinCap_LateFee_Merged', 'FinCap_LateFee_Merged2',\n",
       "       'FinCap_LateFee_MergedYear1', 'Fincap_Goals_IsBlankYear1',\n",
       "       'Fincap_Goals_MergedYear1', 'HasYear2Checkin', 'Income Both',\n",
       "       'IncomeHH_IsBlank_Y1', 'IncomeHH_Merged_Y1', 'Income_Blank',\n",
       "       'Income_Blank2', 'Income_Merged', 'Income_Merged2', 'Savings_Blank',\n",
       "       'Savings_Blank2', 'Savings_IsBlank_Y1', 'Savings_Merged',\n",
       "       'Savings_Merged2', 'Savings_Merged_Y1', 'Wage Both', 'Wage_Blank',\n",
       "       'Wage_Blank2', 'Wage_IsBlank_Y1', 'Wage_Merged', 'Wage_Merged2',\n",
       "       'Wage_Merged_Y1', 'savings Both'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overlap.columns[-82:].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_overlap.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing for 2018Q2 all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We only included data from 2016Q1 to 2018Q2. It's 2 and half years at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\Leah\\Google Drive\\Parent Folder\\2. Clients\\Local\\Dallas\\Communities Foundation of Texas\\Q22018\\Data Work\\ForOverlapAnalysis\\AllData2018Q2_2016-2018_9.20.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency_Baseline</th>\n",
       "      <th>ClientID_Baseline</th>\n",
       "      <th>QuarterBaselineSubmitted</th>\n",
       "      <th>Baseline_Baseline</th>\n",
       "      <th>DOB_Baseline</th>\n",
       "      <th>Year</th>\n",
       "      <th>DOB_Baseline Cat</th>\n",
       "      <th>Gender_Baseline</th>\n",
       "      <th>Race_Baseline</th>\n",
       "      <th>Hispanic_Baseline</th>\n",
       "      <th>...</th>\n",
       "      <th>AccessIncome_All Time</th>\n",
       "      <th>AccessEmployment_All Time2</th>\n",
       "      <th>AccessFinancialCoach_All Time</th>\n",
       "      <th>Bundled Services_All Time</th>\n",
       "      <th>EmploymentStatus_Baseline.1</th>\n",
       "      <th>Employtment Status at Quarterly Checkin</th>\n",
       "      <th>Employment start date at Quarterly Checkin</th>\n",
       "      <th>Months Employed at Quarterly checkin</th>\n",
       "      <th>Months Employed Bin</th>\n",
       "      <th>HasCheckinYear1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCD</td>\n",
       "      <td>1034665</td>\n",
       "      <td>2016 Q2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not employed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCD</td>\n",
       "      <td>1035689</td>\n",
       "      <td>2016 Q1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24850</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>1961-1970</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Employed Part Time</td>\n",
       "      <td>Employed Part Time</td>\n",
       "      <td>2015-11-09 00:00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>More than 2 years</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCD</td>\n",
       "      <td>1035903</td>\n",
       "      <td>2016 Q2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>21103</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>1951-1960</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Employed Part Time</td>\n",
       "      <td>Employed Full Time</td>\n",
       "      <td>2016-01-20 00:00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>More than 2 years</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCD</td>\n",
       "      <td>1036002</td>\n",
       "      <td>2016 Q1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>34128</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1991-2000</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Employed Full Time</td>\n",
       "      <td>Employed Full Time</td>\n",
       "      <td>2015-10-28 00:00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>More than 2 years</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCD</td>\n",
       "      <td>1036147</td>\n",
       "      <td>2016 Q2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>33014</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>1981-1990</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Employed Full Time</td>\n",
       "      <td>Employed Full Time</td>\n",
       "      <td>2016-02-29 00:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>More than 2 years</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Agency_Baseline ClientID_Baseline QuarterBaselineSubmitted  \\\n",
       "0             CCD           1034665                  2016 Q2   \n",
       "1             CCD           1035689                  2016 Q1   \n",
       "2             CCD           1035903                  2016 Q2   \n",
       "3             CCD           1036002                  2016 Q1   \n",
       "4             CCD           1036147                  2016 Q2   \n",
       "\n",
       "  Baseline_Baseline DOB_Baseline    Year DOB_Baseline Cat Gender_Baseline  \\\n",
       "0               Yes          NaN     NaN              NaN          Female   \n",
       "1               Yes        24850  1968.0        1961-1970          Female   \n",
       "2               Yes        21103  1957.0        1951-1960          Female   \n",
       "3               Yes        34128  1993.0        1991-2000            Male   \n",
       "4               Yes        33014  1990.0        1981-1990            Male   \n",
       "\n",
       "               Race_Baseline Hispanic_Baseline       ...        \\\n",
       "0                    Unknown           Unknown       ...         \n",
       "1  Black or African American                No       ...         \n",
       "2                      White                No       ...         \n",
       "3  Black or African American                No       ...         \n",
       "4                      White               Yes       ...         \n",
       "\n",
       "  AccessIncome_All Time AccessEmployment_All Time2  \\\n",
       "0                   Yes                         No   \n",
       "1                   Yes                        Yes   \n",
       "2                   Yes                        Yes   \n",
       "3                    No                        Yes   \n",
       "4                   Yes                         No   \n",
       "\n",
       "  AccessFinancialCoach_All Time  Bundled Services_All Time  \\\n",
       "0                           Yes                        2.0   \n",
       "1                           Yes                        3.0   \n",
       "2                           Yes                        3.0   \n",
       "3                            No                        1.0   \n",
       "4                           Yes                        2.0   \n",
       "\n",
       "   EmploymentStatus_Baseline.1 Employtment Status at Quarterly Checkin  \\\n",
       "0                          NaN                            Not employed   \n",
       "1           Employed Part Time                      Employed Part Time   \n",
       "2           Employed Part Time                      Employed Full Time   \n",
       "3           Employed Full Time                      Employed Full Time   \n",
       "4           Employed Full Time                      Employed Full Time   \n",
       "\n",
       "   Employment start date at Quarterly Checkin  \\\n",
       "0                                         NaN   \n",
       "1                         2015-11-09 00:00:00   \n",
       "2                         2016-01-20 00:00:00   \n",
       "3                         2015-10-28 00:00:00   \n",
       "4                         2016-02-29 00:00:00   \n",
       "\n",
       "  Months Employed at Quarterly checkin  Months Employed Bin HasCheckinYear1  \n",
       "0                                  NaN                  NaN             Yes  \n",
       "1                                 33.0    More than 2 years             Yes  \n",
       "2                                 31.0    More than 2 years             Yes  \n",
       "3                                 33.0    More than 2 years             Yes  \n",
       "4                                 29.0    More than 2 years             Yes  \n",
       "\n",
       "[5 rows x 783 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QuarterBaselineSubmitted',\n",
       " 'Quarter 2016_Q1',\n",
       " 'Quarter 2016_Q2',\n",
       " 'Quarter 2016_Q3',\n",
       " 'Quarter 2016_Q4',\n",
       " 'Quarter 2017_Q1',\n",
       " 'Quarter 2017_Q2',\n",
       " 'Quarter 2017_Q3',\n",
       " 'Quarter 2017_Q4',\n",
       " 'Quarter 2018_Q1',\n",
       " 'Quarter 2018_Q2',\n",
       " 'Employtment Status at Quarterly Checkin',\n",
       " 'Employment start date at Quarterly Checkin',\n",
       " 'Months Employed at Quarterly checkin']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in df.columns if 'Quarter' in m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add HasCheckinYear1 HasCheckinYear2 HasCheckinYear3 into dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NP.WHERE NP.SELECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where   np.select\n",
    "#https://stackoverflow.com/questions/19913659/pandas-conditional-creation-of-a-series-dataframe-column\n",
    "\n",
    "#simple if condition (2 conditions)\n",
    "#https://datatofish.com/if-condition-in-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HasCheckinYear1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5119"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Quarter 2016_Q1'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016 Q1    1005\n",
       "Name: Quarter 2016_Q1, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Quarter 2016_Q1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert blank into Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quarter 2016_Q1']=np.where(df['Quarter 2016_Q1']=='2016 Q1', '2016 Q1', 'NULL')\n",
    "df['Quarter 2016_Q2']=np.where(df['Quarter 2016_Q2']=='2016 Q2', '2016 Q2', 'NULL')\n",
    "df['Quarter 2016_Q3']=np.where(df['Quarter 2016_Q3']=='2016 Q3', '2016 Q3', 'NULL')\n",
    "df['Quarter 2016_Q4']=np.where(df['Quarter 2016_Q4']=='2016 Q4', '2016 Q4', 'NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL       5119\n",
       "2016 Q1    1005\n",
       "Name: Quarter 2016_Q1, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Quarter 2016_Q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions1 = [\n",
    "    (df['Quarter 2016_Q1']=='NULL') & (df['Quarter 2016_Q2']=='NULL')&(df['Quarter 2016_Q3']=='NULL')&(df['Quarter 2016_Q4']=='NULL')\n",
    "]\n",
    "choices1 = ['No']\n",
    "df['HasCheckinYear1'] = np.select(conditions1, choices1, default='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     3743\n",
       "Yes    2381\n",
       "Name: HasCheckinYear1, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HasCheckinYear1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 2398 Yes values for HasCheckinYear1 yay^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HasCheckinYear2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quarter 2017_Q1']=np.where(df['Quarter 2017_Q1']=='2017 Q1', '2017 Q1', 'NULL')\n",
    "df['Quarter 2017_Q2']=np.where(df['Quarter 2017_Q2']=='2017 Q2', '2017 Q2', 'NULL')\n",
    "df['Quarter 2017_Q3']=np.where(df['Quarter 2017_Q3']=='2017 Q3', '2017 Q3', 'NULL')\n",
    "df['Quarter 2017_Q4']=np.where(df['Quarter 2017_Q4']=='2017 Q4', '2017 Q4', 'NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions2 = [\n",
    "    (df['Quarter 2017_Q1']=='NULL') & (df['Quarter 2017_Q2']=='NULL')&(df['Quarter 2017_Q3']=='NULL')&(df['Quarter 2017_Q4']=='NULL')\n",
    "]\n",
    "choices2 = ['No']\n",
    "df['HasCheckinYear2'] = np.select(conditions2, choices2, default='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     3316\n",
       "Yes    2808\n",
       "Name: HasCheckinYear2, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HasCheckinYear2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got 2794 Yes Values for HasCheckinYear2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HasCheckinYear3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quarter 2018_Q1']=np.where(df['Quarter 2018_Q1']=='2018 Q1', '2018 Q1', 'NULL')\n",
    "df['Quarter 2018_Q2']=np.where(df['Quarter 2018_Q2']=='2018 Q2', '2018 Q2', 'NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions3 = [\n",
    "    (df['Quarter 2018_Q1']=='NULL') & (df['Quarter 2018_Q2']=='NULL')\n",
    "]\n",
    "choices3 = ['No']\n",
    "df['HasCheckinYear3'] = np.select(conditions3, choices3, default='Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     3794\n",
       "Yes    2330\n",
       "Name: HasCheckinYear3, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['HasCheckinYear3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got 2330 Yes Values for HasCheckinYear3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Savings_Baseline',\n",
       " 'Savings_Baseline Cat',\n",
       " 'Savings 2016_Q1',\n",
       " 'Savings 2016_Q1 Cat',\n",
       " 'Savings 2016_Q2',\n",
       " 'Savings 2016_Q2 Cat',\n",
       " 'Savings_Checkin 2016_Q3',\n",
       " 'Savings_Checkin 2016_Q3 Cat',\n",
       " 'Savings_Checkin 2016_Q4',\n",
       " 'Savings_Checkin 2016_Q4.1',\n",
       " 'Savings 2017_Q1',\n",
       " 'Savings 2017_Q1 Cat',\n",
       " 'Savings_Checkin_2017Q2',\n",
       " 'Savings_Checkin_CAT_2017Q2',\n",
       " 'Savings_Checkin_2017Q3',\n",
       " 'Savings_Checkin_2017Q3_Cat',\n",
       " 'Savings_Checkin_2017Q4',\n",
       " 'Savings_Checkin_Cat_2017Q4',\n",
       " 'Savings_Checkin_2018Q1',\n",
       " 'Savings_Checkin_Cat_2018Q1',\n",
       " 'Savings_Checkin_2018Q2',\n",
       " 'Savings_Checkin_Cat_2018Q2']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Savings' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Quarterly Savings Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add \n",
    "#### df['Savings_Checkin 2016_Q4_code'] df['Savings_Checkin 2016_Q3_code'] df['Savings 2016_Q2_code'] df['Savings 2016_Q1_code']\n",
    "#### df['Savings_Checkin_2017Q4_code'] df['Savings_Checkin_2017Q3_code'] df['Savings_Checkin_2017Q2_code'] df['Savings 2017_Q1_code']\n",
    "#### df['Savings_Checkin_2018Q2_code'] df['Savings_Checkin_2018Q1_code']\n",
    "### remember to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly savings data\n",
    "#2016\n",
    "df['Savings_Checkin 2016_Q4']=df['Savings_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['Savings_Checkin 2016_Q4_code']=np.where(df['Savings_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Savings_Checkin 2016_Q3']=df['Savings_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['Savings_Checkin 2016_Q3_code']=np.where(df['Savings_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['Savings 2016_Q2']=df['Savings 2016_Q2'].fillna('NULL')\n",
    "df['Savings 2016_Q2_code']=np.where(df['Savings 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['Savings 2016_Q1']=df['Savings 2016_Q1'].fillna('NULL')\n",
    "df['Savings 2016_Q1_code']=np.where(df['Savings 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['Savings_Checkin_2017Q4']=df['Savings_Checkin_2017Q4'].fillna('NULL')\n",
    "df['Savings_Checkin_2017Q4_code']=np.where(df['Savings_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Savings_Checkin_2017Q3']=df['Savings_Checkin_2017Q3'].fillna('NULL')\n",
    "df['Savings_Checkin_2017Q3_code']=np.where(df['Savings_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['Savings_Checkin_2017Q2']=df['Savings_Checkin_2017Q2'].fillna('NULL')\n",
    "df['Savings_Checkin_2017Q2_code']=np.where(df['Savings_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['Savings 2017_Q1']=df['Savings 2017_Q1'].fillna('NULL')\n",
    "df['Savings 2017_Q1_code']=np.where(df['Savings 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['Savings_Checkin_2018Q2']=df['Savings_Checkin_2018Q2'].fillna('NULL')\n",
    "df['Savings_Checkin_2018Q2_code']=np.where(df['Savings_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Savings_Checkin_2018Q1']=df['Savings_Checkin_2018Q1'].fillna('NULL')\n",
    "df['Savings_Checkin_2018Q1_code']=np.where(df['Savings_Checkin_2018Q1']=='NULL', 'NULL', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL    5512\n",
       "1        612\n",
       "Name: Savings_Checkin 2016_Q4_code, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Savings_Checkin 2016_Q4_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL    5574\n",
       "2        550\n",
       "Name: Savings_Checkin 2016_Q3_code, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Savings_Checkin 2016_Q3_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL    5478\n",
       "3        646\n",
       "Name: Savings 2016_Q2_code, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Savings 2016_Q2_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NULL    5331\n",
       "4        793\n",
       "Name: Savings 2016_Q1_code, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Savings 2016_Q1_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Savings function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2016\n",
    "def get_savings_2016(df):\n",
    "    if df['Savings_Checkin 2016_Q4_code']=='1':\n",
    "        return df['Savings_Checkin 2016_Q4']\n",
    "    elif df['Savings_Checkin 2016_Q3_code']=='2':\n",
    "        return df['Savings_Checkin 2016_Q3']\n",
    "    elif df['Savings 2016_Q2_code']=='3':\n",
    "        return df['Savings 2016_Q2']\n",
    "    elif df['Savings 2016_Q1_code']=='4':\n",
    "        return df['Savings 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['Savings_merged_Y1'] = df.apply(get_savings_2016, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Savings_merged_Y1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2017\n",
    "def get_savings_2017(df):\n",
    "    if df['Savings_Checkin_2017Q4_code']=='1':\n",
    "        return df['Savings_Checkin_2017Q4']\n",
    "    elif df['Savings_Checkin_2017Q3_code']=='2':\n",
    "        return df['Savings_Checkin_2017Q3']\n",
    "    elif df['Savings_Checkin_2017Q2_code']=='3':\n",
    "        return df['Savings_Checkin_2017Q2']\n",
    "    elif df['Savings 2017_Q1_code']=='4':\n",
    "        return df['Savings 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['Savings_merged_Y2'] = df.apply(get_savings_2017, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2018\n",
    "def get_savings_2018(df):\n",
    "    if df['Savings_Checkin_2018Q2_code']=='1':\n",
    "        return df['Savings_Checkin_2018Q2']\n",
    "    elif df['Savings_Checkin_2018Q1_code']=='2':\n",
    "        return df['Savings_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['Savings_merged_Y3'] = df.apply(get_savings_2018, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Savings_Baseline',\n",
       " 'Savings_Baseline Cat',\n",
       " 'Savings 2016_Q1',\n",
       " 'Savings 2016_Q1 Cat',\n",
       " 'Savings 2016_Q2',\n",
       " 'Savings 2016_Q2 Cat',\n",
       " 'Savings_Checkin 2016_Q3',\n",
       " 'Savings_Checkin 2016_Q3 Cat',\n",
       " 'Savings_Checkin 2016_Q4',\n",
       " 'Savings_Checkin 2016_Q4.1',\n",
       " 'Savings 2017_Q1',\n",
       " 'Savings 2017_Q1 Cat',\n",
       " 'Savings_Checkin_2017Q2',\n",
       " 'Savings_Checkin_CAT_2017Q2',\n",
       " 'Savings_Checkin_2017Q3',\n",
       " 'Savings_Checkin_2017Q3_Cat',\n",
       " 'Savings_Checkin_2017Q4',\n",
       " 'Savings_Checkin_Cat_2017Q4',\n",
       " 'Savings_Checkin_2018Q1',\n",
       " 'Savings_Checkin_Cat_2018Q1',\n",
       " 'Savings_Checkin_2018Q2',\n",
       " 'Savings_Checkin_Cat_2018Q2',\n",
       " 'Savings_Checkin 2016_Q4_code',\n",
       " 'Savings_Checkin 2016_Q3_code',\n",
       " 'Savings 2016_Q2_code',\n",
       " 'Savings 2016_Q1_code',\n",
       " 'Savings_Checkin_2017Q4_code',\n",
       " 'Savings_Checkin_2017Q3_code',\n",
       " 'Savings_Checkin_2017Q2_code',\n",
       " 'Savings 2017_Q1_code',\n",
       " 'Savings_Checkin_2018Q2_code',\n",
       " 'Savings_Checkin_2018Q1_code',\n",
       " 'Savings_merged_Y1',\n",
       " 'Savings_merged_Y2',\n",
       " 'Savings_merged_Y3']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Savings' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Savings_merged_Y1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Savings_merged_Y2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Savings_merged_Y3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check savings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check savings data\n",
    "df_savings = df[['Savings 2016_Q1','Savings 2016_Q2','Savings_Checkin 2016_Q3','Savings_Checkin 2016_Q4','Savings_merged_Y1',\n",
    "    'Savings 2017_Q1','Savings_Checkin_2017Q2','Savings_Checkin_2017Q3','Savings_Checkin_2017Q4','Savings_merged_Y2',\n",
    "   'Savings_Checkin_2018Q1','Savings_Checkin_2018Q2','Savings_merged_Y3']]\n",
    "df_savings=df_savings.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_savings.to_excel('savings_merged_1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore_Baseline',\n",
       " 'CreditScore_Baseline Cat',\n",
       " 'CreditScore 2016_Q1',\n",
       " 'CreditScore 2016_Q1 Cat',\n",
       " 'CreditScore 2016_Q2',\n",
       " 'CreditScore 2016_Q2 Cat',\n",
       " 'CreditScore_Checkin 2016_Q3',\n",
       " 'CreditScore_Checkin 2016_Q3 Cat',\n",
       " 'CreditScore_Checkin 2016_Q4',\n",
       " 'CreditScore_Checkin 2016_Q4.1',\n",
       " 'CreditScore 2017_Q1',\n",
       " 'CreditScore 2017_Q1 Cat',\n",
       " 'CreditScore_Checkin_2017Q2',\n",
       " 'CreditScore_Checkin_CAT_2017Q2',\n",
       " 'CreditScore_Checkin_2017Q3',\n",
       " 'CreditScore_Checkin_2017Q3 Cat',\n",
       " 'CreditScore_Checkin_2017Q4',\n",
       " 'CreditScore_Checkin_Cat_2017Q4',\n",
       " 'CreditScore_Checkin_2018Q1',\n",
       " 'CreditScore_Checkin_Cat_2018Q1',\n",
       " 'CreditScore_Checkin_2018Q2',\n",
       " 'CreditScore_Checkin_Cat_2018Q2']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'CreditScore' in w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code quarterly credit score\n",
    "### add\n",
    "### df['CreditScore_Checkin 2016_Q4_code'] df['CreditScore_Checkin 2016_Q3_code']df['CreditScore 2016_Q2_code'] df['CreditScore 2016_Q1_code']\n",
    "### CreditScore_Checkin_2017Q4_code CreditScore_Checkin_2017Q3_code CreditScore_Checkin_2017Q2_code 2017_Q1_code\n",
    "### CreditScore_Checkin_2018Q2_code CreditScore_Checkin_2018Q1_code\n",
    "\n",
    "## Remember to drop them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly Credit Score data\n",
    "#2016\n",
    "df['CreditScore_Checkin 2016_Q4']=df['CreditScore_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['CreditScore_Checkin 2016_Q4_code']=np.where(df['CreditScore_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['CreditScore_Checkin 2016_Q3']=df['CreditScore_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['CreditScore_Checkin 2016_Q3_code']=np.where(df['CreditScore_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['CreditScore 2016_Q2']=df['CreditScore 2016_Q2'].fillna('NULL')\n",
    "df['CreditScore 2016_Q2_code']=np.where(df['CreditScore 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['CreditScore 2016_Q1']=df['CreditScore 2016_Q1'].fillna('NULL')\n",
    "df['CreditScore 2016_Q1_code']=np.where(df['CreditScore 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['CreditScore_Checkin_2017Q4']=df['CreditScore_Checkin_2017Q4'].fillna('NULL')\n",
    "df['CreditScore_Checkin_2017Q4_code']=np.where(df['CreditScore_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['CreditScore_Checkin_2017Q3']=df['CreditScore_Checkin_2017Q3'].fillna('NULL')\n",
    "df['CreditScore_Checkin_2017Q3_code']=np.where(df['CreditScore_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['CreditScore_Checkin_2017Q2']=df['CreditScore_Checkin_2017Q2'].fillna('NULL')\n",
    "df['CreditScore_Checkin_2017Q2_code']=np.where(df['CreditScore_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['CreditScore 2017_Q1']=df['CreditScore 2017_Q1'].fillna('NULL')\n",
    "df['CreditScore 2017_Q1_code']=np.where(df['CreditScore 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['CreditScore_Checkin_2018Q2']=df['CreditScore_Checkin_2018Q2'].fillna('NULL')\n",
    "df['CreditScore_Checkin_2018Q2_code']=np.where(df['CreditScore_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['CreditScore_Checkin_2018Q1']=df['CreditScore_Checkin_2018Q1'].fillna('NULL')\n",
    "df['CreditScore_Checkin_2018Q1_code']=np.where(df['CreditScore_Checkin_2018Q1']=='NULL', 'NULL', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2016\n",
    "def get_creditscore_2016(df):\n",
    "    if df['CreditScore_Checkin 2016_Q4_code']=='1':\n",
    "        return df['CreditScore_Checkin 2016_Q4']\n",
    "    elif df['CreditScore_Checkin 2016_Q3_code']=='2':\n",
    "        return df['CreditScore_Checkin 2016_Q3']\n",
    "    elif df['CreditScore 2016_Q2_code']=='3':\n",
    "        return df['CreditScore 2016_Q2']\n",
    "    elif df['CreditScore 2016_Q1_code']=='4':\n",
    "        return df['CreditScore 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['CreditScore_merged_Y1'] = df.apply(get_creditscore_2016, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2017\n",
    "def get_creditscore_2017(df):\n",
    "    if df['CreditScore_Checkin_2017Q4_code']=='1':\n",
    "        return df['CreditScore_Checkin_2017Q4']\n",
    "    elif df['CreditScore_Checkin_2017Q3_code']=='2':\n",
    "        return df['CreditScore_Checkin_2017Q3']\n",
    "    elif df['CreditScore_Checkin_2017Q2_code']=='3':\n",
    "        return df['CreditScore_Checkin_2017Q2']\n",
    "    elif df['CreditScore 2017_Q1_code']=='4':\n",
    "        return df['CreditScore 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['CreditScore_merged_Y2'] = df.apply(get_creditscore_2017, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2018\n",
    "def get_creditscore_2018(df):\n",
    "    if df['CreditScore_Checkin_2018Q2_code']=='1':\n",
    "        return df['CreditScore_Checkin_2018Q2']\n",
    "    elif df['CreditScore_Checkin_2018Q1_code']=='2':\n",
    "        return df['CreditScore_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['CreditScore_merged_Y3'] = df.apply(get_creditscore_2018, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check creditscore data\n",
    "df_creditscore = df[['CreditScore 2016_Q1','CreditScore 2016_Q2','CreditScore_Checkin 2016_Q3','CreditScore_Checkin 2016_Q4','CreditScore_merged_Y1',\n",
    "    'CreditScore 2017_Q1','CreditScore_Checkin_2017Q2','CreditScore_Checkin_2017Q3','CreditScore_Checkin_2017Q4','CreditScore_merged_Y2',\n",
    "   'CreditScore_Checkin_2018Q1','CreditScore_Checkin_2018Q2','CreditScore_merged_Y3']]\n",
    "df_creditscore=df_creditscore.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_creditscore.to_excel('creditscore_check_9.24.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Debt_Baseline',\n",
       " 'Debt_Baseline Cat',\n",
       " 'Debt 2016_Q1',\n",
       " 'Debt 2016_Q1 Cat',\n",
       " 'Debt 2016_Q2',\n",
       " 'Debt 2016_Q2 Cat',\n",
       " 'Debt_Checkin 2016_Q3',\n",
       " 'Debt_Checkin 2016_Q3 Cat',\n",
       " 'Debt_Checkin 2016_Q4',\n",
       " 'Debt_Checkin 2016_Q4.1',\n",
       " 'Debt 2017_Q1',\n",
       " 'Debt 2017_Q1 Cat',\n",
       " 'Debt_Checkin_2017Q2',\n",
       " 'Debt_Checkin_CAT_2017Q2',\n",
       " 'Debt_Checkin_2017Q3',\n",
       " 'Debt_Checkin_2017Q3 Cat',\n",
       " 'Debt_Checkin_2017Q4',\n",
       " 'Debt_Checkin_Cat_2017Q4',\n",
       " 'Debt_Checkin_2018Q1',\n",
       " 'Debt_Checkin_Cat_2018Q1',\n",
       " 'Debt_Checkin_2018Q2',\n",
       " 'Debt_Checkin_Cat_2018Q2']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Debt' in w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add\n",
    "### Debt_Checkin 2016_Q4_code  Debt_Checkin 2016_Q3_code  Debt 2016_Q2_code  Debt 2016_Q1_code\n",
    "### Debt_Checkin_2017Q4_code  Debt_Checkin_2017Q3_code  Debt_Checkin_2017Q2_code  Debt 2017_Q1_code\n",
    "### Debt_Checkin_2018Q2_code  Debt_Checkin_2018Q1_code\n",
    "## Remember to drop them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly Debt data\n",
    "#2016\n",
    "df['Debt_Checkin 2016_Q4']=df['Debt_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['Debt_Checkin 2016_Q4_code']=np.where(df['Debt_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Debt_Checkin 2016_Q3']=df['Debt_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['Debt_Checkin 2016_Q3_code']=np.where(df['Debt_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['Debt 2016_Q2']=df['Debt 2016_Q2'].fillna('NULL')\n",
    "df['Debt 2016_Q2_code']=np.where(df['Debt 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['Debt 2016_Q1']=df['Debt 2016_Q1'].fillna('NULL')\n",
    "df['Debt 2016_Q1_code']=np.where(df['Debt 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['Debt_Checkin_2017Q4']=df['Debt_Checkin_2017Q4'].fillna('NULL')\n",
    "df['Debt_Checkin_2017Q4_code']=np.where(df['Debt_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Debt_Checkin_2017Q3']=df['Debt_Checkin_2017Q3'].fillna('NULL')\n",
    "df['Debt_Checkin_2017Q3_code']=np.where(df['Debt_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['Debt_Checkin_2017Q2']=df['Debt_Checkin_2017Q2'].fillna('NULL')\n",
    "df['Debt_Checkin_2017Q2_code']=np.where(df['Debt_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['Debt 2017_Q1']=df['Debt 2017_Q1'].fillna('NULL')\n",
    "df['Debt 2017_Q1_code']=np.where(df['Debt 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['Debt_Checkin_2018Q2']=df['Debt_Checkin_2018Q2'].fillna('NULL')\n",
    "df['Debt_Checkin_2018Q2_code']=np.where(df['Debt_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Debt_Checkin_2018Q1']=df['Debt_Checkin_2018Q1'].fillna('NULL')\n",
    "df['Debt_Checkin_2018Q1_code']=np.where(df['Debt_Checkin_2018Q1']=='NULL', 'NULL', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2016\n",
    "def get_debt_2016(df):\n",
    "    if df['Debt_Checkin 2016_Q4_code']=='1':\n",
    "        return df['Debt_Checkin 2016_Q4']\n",
    "    elif df['Debt_Checkin 2016_Q3_code']=='2':\n",
    "        return df['Debt_Checkin 2016_Q3']\n",
    "    elif df['Debt 2016_Q2_code']=='3':\n",
    "        return df['Debt 2016_Q2']\n",
    "    elif df['Debt 2016_Q1_code']=='4':\n",
    "        return df['Debt 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['Debt_merged_Y1'] = df.apply(get_debt_2016, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2017\n",
    "def get_debt_2017(df):\n",
    "    if df['Debt_Checkin_2017Q4_code']=='1':\n",
    "        return df['Debt_Checkin_2017Q4']\n",
    "    elif df['Debt_Checkin_2017Q3_code']=='2':\n",
    "        return df['Debt_Checkin_2017Q3']\n",
    "    elif df['Debt_Checkin_2017Q2_code']=='3':\n",
    "        return df['Debt_Checkin_2017Q2']\n",
    "    elif df['Debt 2017_Q1_code']=='4':\n",
    "        return df['Debt 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['Debt_merged_Y2'] = df.apply(get_debt_2017, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2018\n",
    "def get_debt_2018(df):\n",
    "    if df['Debt_Checkin_2018Q2_code']=='1':\n",
    "        return df['Debt_Checkin_2018Q2']\n",
    "    elif df['Debt_Checkin_2018Q1_code']=='2':\n",
    "        return df['Debt_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['Debt_merged_Y3'] = df.apply(get_debt_2018, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check debt data\n",
    "df_debt = df[['Debt 2016_Q1','Debt 2016_Q2','Debt_Checkin 2016_Q3','Debt_Checkin 2016_Q4','Debt_merged_Y1',\n",
    "    'Debt 2017_Q1','Debt_Checkin_2017Q2','Debt_Checkin_2017Q3','Debt_Checkin_2017Q4','Debt_merged_Y2',\n",
    "   'Debt_Checkin_2018Q1','Debt_Checkin_2018Q2','Debt_merged_Y3']]\n",
    "df_debt=df_debt.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_debt.to_excel('debt_check_9.24.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wage\n",
    "### used wage1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wages1_Baseline',\n",
       " 'Wages1_Baseline Cat',\n",
       " 'Wages1 2016_Q1',\n",
       " 'Wages1 2016_Q1 Cat',\n",
       " 'Wages1and2Combined 2016_Q1',\n",
       " 'Wages1 2016_Q2',\n",
       " 'Wages1 2016_Q2 Cat',\n",
       " 'Wages1_Checkin 2016_Q3',\n",
       " 'Wages1_Checkin 2016_Q3 Cat',\n",
       " 'Wages1_Checkin 2016_Q4',\n",
       " 'Wages1_Checkin 2016_Q4 Cat',\n",
       " 'Wages1 2017_Q1',\n",
       " 'Wages1 2017_Q1 Cat',\n",
       " 'Wages1_Checkin_2017Q2',\n",
       " 'Wages1_Checkin_CAT_2017Q2',\n",
       " 'Wages1_Checkin_2017Q3',\n",
       " 'Wages1_Checkin_2017Q3 Cat',\n",
       " 'Wages1_Checkin_2017Q4',\n",
       " 'Wages1_Checkin_2018Q1',\n",
       " 'Wages1_Checkin_2018Q2']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Wages1' in w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added code columns remember to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly wages1 data\n",
    "#2016\n",
    "df['Wages1_Checkin 2016_Q4']=df['Wages1_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['Wages1_Checkin 2016_Q4_code']=np.where(df['Wages1_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Wages1_Checkin 2016_Q3']=df['Wages1_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['Wages1_Checkin 2016_Q3_code']=np.where(df['Wages1_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['Wages1 2016_Q2']=df['Wages1 2016_Q2'].fillna('NULL')\n",
    "df['Wages1 2016_Q2_code']=np.where(df['Wages1 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['Wages1 2016_Q1']=df['Wages1 2016_Q1'].fillna('NULL')\n",
    "df['Wages1 2016_Q1_code']=np.where(df['Wages1 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['Wages1_Checkin_2017Q4']=df['Wages1_Checkin_2017Q4'].fillna('NULL')\n",
    "df['Wages1_Checkin_2017Q4_code']=np.where(df['Wages1_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Wages1_Checkin_2017Q3']=df['Wages1_Checkin_2017Q3'].fillna('NULL')\n",
    "df['Wages1_Checkin_2017Q3_code']=np.where(df['Wages1_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['Wages1_Checkin_2017Q2']=df['Wages1_Checkin_2017Q2'].fillna('NULL')\n",
    "df['Wages1_Checkin_2017Q2_code']=np.where(df['Wages1_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['Wages1 2017_Q1']=df['Wages1 2017_Q1'].fillna('NULL')\n",
    "df['Wages1 2017_Q1_code']=np.where(df['Wages1 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['Wages1_Checkin_2018Q2']=df['Wages1_Checkin_2018Q2'].fillna('NULL')\n",
    "df['Wages1_Checkin_2018Q2_code']=np.where(df['Wages1_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Wages1_Checkin_2018Q1']=df['Wages1_Checkin_2018Q1'].fillna('NULL')\n",
    "df['Wages1_Checkin_2018Q1_code']=np.where(df['Wages1_Checkin_2018Q1']=='NULL', 'NULL', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2016\n",
    "def get_wages1_2016(df):\n",
    "    if df['Wages1_Checkin 2016_Q4_code']=='1':\n",
    "        return df['Wages1_Checkin 2016_Q4']\n",
    "    elif df['Wages1_Checkin 2016_Q3_code']=='2':\n",
    "        return df['Wages1_Checkin 2016_Q3']\n",
    "    elif df['Wages1 2016_Q2_code']=='3':\n",
    "        return df['Wages1 2016_Q2']\n",
    "    elif df['Wages1 2016_Q1_code']=='4':\n",
    "        return df['Wages1 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['Wages1_merged_Y1'] = df.apply(get_wages1_2016, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2017\n",
    "def get_wages1_2017(df):\n",
    "    if df['Wages1_Checkin_2017Q4_code']=='1':\n",
    "        return df['Wages1_Checkin_2017Q4']\n",
    "    elif df['Wages1_Checkin_2017Q3_code']=='2':\n",
    "        return df['Wages1_Checkin_2017Q3']\n",
    "    elif df['Wages1_Checkin_2017Q2_code']=='3':\n",
    "        return df['Wages1_Checkin_2017Q2']\n",
    "    elif df['Wages1 2017_Q1_code']=='4':\n",
    "        return df['Wages1 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['Wages1_merged_Y2'] = df.apply(get_wages1_2017, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2018\n",
    "def get_wages1_2018(df):\n",
    "    if df['Wages1_Checkin_2018Q2_code']=='1':\n",
    "        return df['Wages1_Checkin_2018Q2']\n",
    "    elif df['Wages1_Checkin_2018Q1_code']=='2':\n",
    "        return df['Wages1_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['Wages1_merged_Y3'] = df.apply(get_wages1_2018, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check Wages1 data\n",
    "df_wages1 = df[['Wages1 2016_Q1','Wages1 2016_Q2','Wages1_Checkin 2016_Q3','Wages1_Checkin 2016_Q4','Wages1_merged_Y1',\n",
    "    'Wages1 2017_Q1','Wages1_Checkin_2017Q2','Wages1_Checkin_2017Q3','Wages1_Checkin_2017Q4','Wages1_merged_Y2',\n",
    "   'Wages1_Checkin_2018Q1','Wages1_Checkin_2018Q2','Wages1_merged_Y3']]\n",
    "df_wages1=df_wages1.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_wages1.to_excel('wages1_check_9.24.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IncomeHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IncomeHH_Baseline',\n",
       " 'IncomeHH_Baseline Cat',\n",
       " 'IncomeHH 2016_Q1',\n",
       " 'IncomeHH 2016_Q1 Cat',\n",
       " 'IncomeHH 2016_Q2',\n",
       " 'IncomeHH 2016_Q2 Cat',\n",
       " 'IncomeHH_Checkin 2016_Q3',\n",
       " 'IncomeHH_Checkin 2016_Q3 Cat',\n",
       " 'IncomeHH_Checkin 2016_Q4',\n",
       " 'IncomeHH_Checkin 2016_Q4.1',\n",
       " 'IncomeHH 2017_Q1',\n",
       " 'IncomeHH 2017_Q1 Cat',\n",
       " 'IncomeHH_Checkin_2017Q2',\n",
       " 'IncomeHH_Checkin_CAT_2017Q2',\n",
       " 'IncomeHH_Checkin_2017Q3',\n",
       " 'IncomeHH_Checkin_2017Q3 Cat',\n",
       " 'IncomeHH_Checkin_2017Q4',\n",
       " 'IncomeHH_Checkin_Cat_2017Q4',\n",
       " 'IncomeHH_Checkin_2018Q1',\n",
       " 'IncomeHH_Checkin_Cat_2018Q1',\n",
       " 'IncomeHH_Checkin_2018Q2',\n",
       " 'IncomeHH_Checkin_Cat_2018Q2']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'IncomeHH' in w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Quarterly IncomeHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly IncomeHH data\n",
    "#2016\n",
    "df['IncomeHH_Checkin 2016_Q4']=df['IncomeHH_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['IncomeHH_Checkin 2016_Q4_code']=np.where(df['IncomeHH_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['IncomeHH_Checkin 2016_Q3']=df['IncomeHH_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['IncomeHH_Checkin 2016_Q3_code']=np.where(df['IncomeHH_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['IncomeHH 2016_Q2']=df['IncomeHH 2016_Q2'].fillna('NULL')\n",
    "df['IncomeHH 2016_Q2_code']=np.where(df['IncomeHH 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['IncomeHH 2016_Q1']=df['IncomeHH 2016_Q1'].fillna('NULL')\n",
    "df['IncomeHH 2016_Q1_code']=np.where(df['IncomeHH 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['IncomeHH_Checkin_2017Q4']=df['IncomeHH_Checkin_2017Q4'].fillna('NULL')\n",
    "df['IncomeHH_Checkin_2017Q4_code']=np.where(df['IncomeHH_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['IncomeHH_Checkin_2017Q3']=df['IncomeHH_Checkin_2017Q3'].fillna('NULL')\n",
    "df['IncomeHH_Checkin_2017Q3_code']=np.where(df['IncomeHH_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['IncomeHH_Checkin_2017Q2']=df['IncomeHH_Checkin_2017Q2'].fillna('NULL')\n",
    "df['IncomeHH_Checkin_2017Q2_code']=np.where(df['IncomeHH_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['IncomeHH 2017_Q1']=df['IncomeHH 2017_Q1'].fillna('NULL')\n",
    "df['IncomeHH 2017_Q1_code']=np.where(df['IncomeHH 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['IncomeHH_Checkin_2018Q2']=df['IncomeHH_Checkin_2018Q2'].fillna('NULL')\n",
    "df['IncomeHH_Checkin_2018Q2_code']=np.where(df['IncomeHH_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['IncomeHH_Checkin_2018Q1']=df['IncomeHH_Checkin_2018Q1'].fillna('NULL')\n",
    "df['IncomeHH_Checkin_2018Q1_code']=np.where(df['IncomeHH_Checkin_2018Q1']=='NULL', 'NULL', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2016\n",
    "def get_incomeHH_2016(df):\n",
    "    if df['IncomeHH_Checkin 2016_Q4_code']=='1':\n",
    "        return df['IncomeHH_Checkin 2016_Q4']\n",
    "    elif df['IncomeHH_Checkin 2016_Q3_code']=='2':\n",
    "        return df['IncomeHH_Checkin 2016_Q3']\n",
    "    elif df['IncomeHH 2016_Q2_code']=='3':\n",
    "        return df['IncomeHH 2016_Q2']\n",
    "    elif df['IncomeHH 2016_Q1_code']=='4':\n",
    "        return df['IncomeHH 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['IncomeHH_merged_Y1'] = df.apply(get_incomeHH_2016, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2017\n",
    "def get_incomeHH_2017(df):\n",
    "    if df['IncomeHH_Checkin_2017Q4_code']=='1':\n",
    "        return df['IncomeHH_Checkin_2017Q4']\n",
    "    elif df['IncomeHH_Checkin_2017Q3_code']=='2':\n",
    "        return df['IncomeHH_Checkin_2017Q3']\n",
    "    elif df['IncomeHH_Checkin_2017Q2_code']=='3':\n",
    "        return df['IncomeHH_Checkin_2017Q2']\n",
    "    elif df['IncomeHH 2017_Q1_code']=='4':\n",
    "        return df['IncomeHH 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['IncomeHH_merged_Y2'] = df.apply(get_incomeHH_2017, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2018\n",
    "def get_incomeHH_2018(df):\n",
    "    if df['IncomeHH_Checkin_2018Q2_code']=='1':\n",
    "        return df['IncomeHH_Checkin_2018Q2']\n",
    "    elif df['IncomeHH_Checkin_2018Q1_code']=='2':\n",
    "        return df['IncomeHH_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['IncomeHH_merged_Y3'] = df.apply(get_incomeHH_2018, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check IncomeHH data\n",
    "df_IncomeHH = df[['IncomeHH 2016_Q1','IncomeHH 2016_Q2','IncomeHH_Checkin 2016_Q3','IncomeHH_Checkin 2016_Q4','IncomeHH_merged_Y1',\n",
    "                  'IncomeHH 2017_Q1','IncomeHH_Checkin_2017Q2','IncomeHH_Checkin_2017Q3','IncomeHH_Checkin_2017Q4','IncomeHH_merged_Y2',\n",
    "                  'IncomeHH_Checkin_2018Q1','IncomeHH_Checkin_2018Q2','IncomeHH_merged_Y3']]\n",
    "df_IncomeHH=df_IncomeHH.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_IncomeHH.to_excel('IncomeHH_check_9.24.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinCap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinCap_LateFee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FinCap_LateFee_Baseline',\n",
       " 'FinCap_LateFee 2016_Q1',\n",
       " 'FinCap_LateFee 2016_Q2',\n",
       " 'FinCap_LateFee_Checkin 2016_Q3',\n",
       " 'FinCap_LateFee_Checkin 2016_Q4',\n",
       " 'FinCap_LateFee 2017_Q1',\n",
       " 'FinCap_LateFee_Checkin_2017Q2',\n",
       " 'FinCap_LateFee_Checkin_2017Q3',\n",
       " 'FinCap_LateFee_Checkin_2017Q4',\n",
       " 'FinCap_LateFee_Checkin_2018Q1',\n",
       " 'FinCap_LateFee_Checkin_2018Q2']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'FinCap_LateFee' in w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Quarterly Fincap_LateFee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly Fincap_LateFee data\n",
    "#2016\n",
    "df['FinCap_LateFee_Checkin 2016_Q4']=df['FinCap_LateFee_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['FinCap_LateFee_Checkin 2016_Q4_code']=np.where(df['FinCap_LateFee_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_LateFee_Checkin 2016_Q3']=df['FinCap_LateFee_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['FinCap_LateFee_Checkin 2016_Q3_code']=np.where(df['FinCap_LateFee_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_LateFee 2016_Q2']=df['FinCap_LateFee 2016_Q2'].fillna('NULL')\n",
    "df['FinCap_LateFee 2016_Q2_code']=np.where(df['FinCap_LateFee 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_LateFee 2016_Q1']=df['FinCap_LateFee 2016_Q1'].fillna('NULL')\n",
    "df['FinCap_LateFee 2016_Q1_code']=np.where(df['FinCap_LateFee 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['FinCap_LateFee_Checkin_2017Q4']=df['FinCap_LateFee_Checkin_2017Q4'].fillna('NULL')\n",
    "df['FinCap_LateFee_Checkin_2017Q4_code']=np.where(df['FinCap_LateFee_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_LateFee_Checkin_2017Q3']=df['FinCap_LateFee_Checkin_2017Q3'].fillna('NULL')\n",
    "df['FinCap_LateFee_Checkin_2017Q3_code']=np.where(df['FinCap_LateFee_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_LateFee_Checkin_2017Q2']=df['FinCap_LateFee_Checkin_2017Q2'].fillna('NULL')\n",
    "df['FinCap_LateFee_Checkin_2017Q2_code']=np.where(df['FinCap_LateFee_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_LateFee 2017_Q1']=df['FinCap_LateFee 2017_Q1'].fillna('NULL')\n",
    "df['FinCap_LateFee 2017_Q1_code']=np.where(df['FinCap_LateFee 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['FinCap_LateFee_Checkin_2018Q2']=df['FinCap_LateFee_Checkin_2018Q2'].fillna('NULL')\n",
    "df['FinCap_LateFee_Checkin_2018Q2_code']=np.where(df['FinCap_LateFee_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_LateFee_Checkin_2018Q1']=df['FinCap_LateFee_Checkin_2018Q1'].fillna('NULL')\n",
    "df['FinCap_LateFee_Checkin_2018Q1_code']=np.where(df['FinCap_LateFee_Checkin_2018Q1']=='NULL', 'NULL', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2016\n",
    "def get_FincapLateFee_2016(df):\n",
    "    if df['FinCap_LateFee_Checkin 2016_Q4_code']=='1':\n",
    "        return df['FinCap_LateFee_Checkin 2016_Q4']\n",
    "    elif df['FinCap_LateFee_Checkin 2016_Q3_code']=='2':\n",
    "        return df['FinCap_LateFee_Checkin 2016_Q3']\n",
    "    elif df['FinCap_LateFee 2016_Q2_code']=='3':\n",
    "        return df['FinCap_LateFee 2016_Q2']\n",
    "    elif df['FinCap_LateFee 2016_Q1_code']=='4':\n",
    "        return df['FinCap_LateFee 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapLateFee_merged_Y1'] = df.apply(get_FincapLateFee_2016, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2017\n",
    "def get_FincapLateFee_2017(df):\n",
    "    if df['FinCap_LateFee_Checkin_2017Q4_code']=='1':\n",
    "        return df['FinCap_LateFee_Checkin_2017Q4']\n",
    "    elif df['FinCap_LateFee_Checkin_2017Q3_code']=='2':\n",
    "        return df['FinCap_LateFee_Checkin_2017Q3']\n",
    "    elif df['FinCap_LateFee_Checkin_2017Q2_code']=='3':\n",
    "        return df['FinCap_LateFee_Checkin_2017Q2']\n",
    "    elif df['FinCap_LateFee 2017_Q1_code']=='4':\n",
    "        return df['FinCap_LateFee 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapLateFee_merged_Y2'] = df.apply(get_FincapLateFee_2017, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2018\n",
    "def get_FincapLateFee_2018(df):\n",
    "    if df['FinCap_LateFee_Checkin_2018Q2_code']=='1':\n",
    "        return df['FinCap_LateFee_Checkin_2018Q2']\n",
    "    elif df['FinCap_LateFee_Checkin_2018Q1_code']=='2':\n",
    "        return df['FinCap_LateFee_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['FincapLateFee_merged_Y3'] = df.apply(get_FincapLateFee_2018, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check FincapLateFee data\n",
    "df_FincapLateFee = df[['FinCap_LateFee 2016_Q1','FinCap_LateFee 2016_Q2','FinCap_LateFee_Checkin 2016_Q3','FinCap_LateFee_Checkin 2016_Q4','FincapLateFee_merged_Y1',\n",
    "                  'FinCap_LateFee 2017_Q1','FinCap_LateFee_Checkin_2017Q2','FinCap_LateFee_Checkin_2017Q3','FinCap_LateFee_Checkin_2017Q4','FincapLateFee_merged_Y2',\n",
    "                  'FinCap_LateFee_Checkin_2018Q1','FinCap_LateFee_Checkin_2018Q2','FincapLateFee_merged_Y3']]\n",
    "df_FincapLateFee=df_FincapLateFee.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_FincapLateFee.to_excel('FincapLateFee_check_9.24.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinCap_IncomeExpenses_Merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FinCap_IncomeExpenses_Baseline',\n",
       " 'FinCap_IncomeExpenses 2016_Q1',\n",
       " 'FinCap_IncomeExpenses 2016_Q2',\n",
       " 'FinCap_IncomeExpenses_Checkin 2016_Q3',\n",
       " 'FinCap_IncomeExpenses_Checkin 2016_Q4',\n",
       " 'FinCap_IncomeExpenses 2017_Q1',\n",
       " 'FinCap_IncomeExpenses_Checkin_2017Q2',\n",
       " 'FinCap_IncomeExpenses_Checkin_2017Q3',\n",
       " 'FinCap_IncomeExpenses_Checkin_2017Q4',\n",
       " 'FinCap_IncomeExpenses_Checkin_2018Q1',\n",
       " 'FinCap_IncomeExpenses_Checkin_2018Q2']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'FinCap_Income' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly Fincap_IncomeExpenses data\n",
    "#2016\n",
    "df['FinCap_IncomeExpenses_Checkin 2016_Q4']=df['FinCap_IncomeExpenses_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses_Checkin 2016_Q4_code']=np.where(df['FinCap_IncomeExpenses_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_IncomeExpenses_Checkin 2016_Q3']=df['FinCap_IncomeExpenses_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses_Checkin 2016_Q3_code']=np.where(df['FinCap_IncomeExpenses_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_IncomeExpenses 2016_Q2']=df['FinCap_IncomeExpenses 2016_Q2'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses 2016_Q2_code']=np.where(df['FinCap_IncomeExpenses 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_IncomeExpenses 2016_Q1']=df['FinCap_IncomeExpenses 2016_Q1'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses 2016_Q1_code']=np.where(df['FinCap_IncomeExpenses 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['FinCap_IncomeExpenses_Checkin_2017Q4']=df['FinCap_IncomeExpenses_Checkin_2017Q4'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses_Checkin_2017Q4_code']=np.where(df['FinCap_IncomeExpenses_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_IncomeExpenses_Checkin_2017Q3']=df['FinCap_IncomeExpenses_Checkin_2017Q3'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses_Checkin_2017Q3_code']=np.where(df['FinCap_IncomeExpenses_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_IncomeExpenses_Checkin_2017Q2']=df['FinCap_IncomeExpenses_Checkin_2017Q2'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses_Checkin_2017Q2_code']=np.where(df['FinCap_IncomeExpenses_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_IncomeExpenses 2017_Q1']=df['FinCap_IncomeExpenses 2017_Q1'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses 2017_Q1_code']=np.where(df['FinCap_IncomeExpenses 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['FinCap_IncomeExpenses_Checkin_2018Q2']=df['FinCap_IncomeExpenses_Checkin_2018Q2'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses_Checkin_2018Q2_code']=np.where(df['FinCap_IncomeExpenses_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_IncomeExpenses_Checkin_2018Q1']=df['FinCap_IncomeExpenses_Checkin_2018Q1'].fillna('NULL')\n",
    "df['FinCap_IncomeExpenses_Checkin_2018Q1_code']=np.where(df['FinCap_IncomeExpenses_Checkin_2018Q1']=='NULL', 'NULL', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2016\n",
    "def get_FincapIncomeExpenses_2016(df):\n",
    "    if df['FinCap_IncomeExpenses_Checkin 2016_Q4_code']=='1':\n",
    "        return df['FinCap_IncomeExpenses_Checkin 2016_Q4']\n",
    "    elif df['FinCap_IncomeExpenses_Checkin 2016_Q3_code']=='2':\n",
    "        return df['FinCap_IncomeExpenses_Checkin 2016_Q3']\n",
    "    elif df['FinCap_IncomeExpenses 2016_Q2_code']=='3':\n",
    "        return df['FinCap_IncomeExpenses 2016_Q2']\n",
    "    elif df['FinCap_IncomeExpenses 2016_Q1_code']=='4':\n",
    "        return df['FinCap_IncomeExpenses 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapIncomeExpenses_merged_Y1'] = df.apply(get_FincapIncomeExpenses_2016, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2017\n",
    "def get_FincapIncomeExpenses_2017(df):\n",
    "    if df['FinCap_IncomeExpenses_Checkin_2017Q4_code']=='1':\n",
    "        return df['FinCap_IncomeExpenses_Checkin_2017Q4']\n",
    "    elif df['FinCap_IncomeExpenses_Checkin_2017Q3_code']=='2':\n",
    "        return df['FinCap_IncomeExpenses_Checkin_2017Q3']\n",
    "    elif df['FinCap_IncomeExpenses_Checkin_2017Q2_code']=='3':\n",
    "        return df['FinCap_IncomeExpenses_Checkin_2017Q2']\n",
    "    elif df['FinCap_IncomeExpenses 2017_Q1_code']=='4':\n",
    "        return df['FinCap_IncomeExpenses 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapIncomeExpenses_merged_Y2'] = df.apply(get_FincapIncomeExpenses_2017, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2018\n",
    "def get_FincapIncomeExpenses_2018(df):\n",
    "    if df['FinCap_IncomeExpenses_Checkin_2018Q2_code']=='1':\n",
    "        return df['FinCap_IncomeExpenses_Checkin_2018Q2']\n",
    "    elif df['FinCap_IncomeExpenses_Checkin_2018Q1_code']=='2':\n",
    "        return df['FinCap_LateFee_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['FincapIncomeExpenses_merged_Y3'] = df.apply(get_FincapIncomeExpenses_2018, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check FincapLateFee data\n",
    "df_FincapIncomeExpenses = df[['FinCap_IncomeExpenses 2016_Q1','FinCap_IncomeExpenses 2016_Q2','FinCap_IncomeExpenses_Checkin 2016_Q3','FinCap_IncomeExpenses_Checkin 2016_Q4','FincapIncomeExpenses_merged_Y1',\n",
    "                  'FinCap_IncomeExpenses 2017_Q1','FinCap_IncomeExpenses_Checkin_2017Q2','FinCap_IncomeExpenses_Checkin_2017Q3','FinCap_IncomeExpenses_Checkin_2017Q4','FincapIncomeExpenses_merged_Y2',\n",
    "                  'FinCap_IncomeExpenses_Checkin_2018Q1','FinCap_IncomeExpenses_Checkin_2018Q2','FincapIncomeExpenses_merged_Y3']]\n",
    "df_FincapIncomeExpenses=df_FincapIncomeExpenses.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FincapIncomeExpenses.to_excel('FincapIncomeExpenses_check_9.24.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinCap_AutoDeposit_Merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FinCap_AutoDeposit_Baseline',\n",
       " 'FinCap_AutoDeposit 2016_Q1',\n",
       " 'FinCap_AutoDeposit 2016_Q2',\n",
       " 'FinCap_AutoDeposit_Checkin 2016_Q3',\n",
       " 'FinCap_AutoDeposit_Checkin 2016_Q4',\n",
       " 'FinCap_AutoDeposit 2017_Q1',\n",
       " 'FinCap_AutoDeposit_Checkin_2017Q2',\n",
       " 'FinCap_AutoDeposit_Checkin_2017Q3',\n",
       " 'FinCap_AutoDeposit_Checkin_2017Q4',\n",
       " 'FinCap_AutoDeposit_Checkin_2018Q1',\n",
       " 'FinCap_AutoDeposit_Checkin_2018Q2']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'FinCap_AutoDeposit' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly Fincap_AutoDeposit data\n",
    "#2016\n",
    "df['FinCap_AutoDeposit_Checkin 2016_Q4']=df['FinCap_AutoDeposit_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit_Checkin 2016_Q4_code']=np.where(df['FinCap_AutoDeposit_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_AutoDeposit_Checkin 2016_Q3']=df['FinCap_AutoDeposit_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit_Checkin 2016_Q3_code']=np.where(df['FinCap_AutoDeposit_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_AutoDeposit 2016_Q2']=df['FinCap_AutoDeposit 2016_Q2'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit 2016_Q2_code']=np.where(df['FinCap_AutoDeposit 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_AutoDeposit 2016_Q1']=df['FinCap_AutoDeposit 2016_Q1'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit 2016_Q1_code']=np.where(df['FinCap_AutoDeposit 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['FinCap_AutoDeposit_Checkin_2017Q4']=df['FinCap_AutoDeposit_Checkin_2017Q4'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit_Checkin_2017Q4_code']=np.where(df['FinCap_AutoDeposit_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_AutoDeposit_Checkin_2017Q3']=df['FinCap_AutoDeposit_Checkin_2017Q3'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit_Checkin_2017Q3_code']=np.where(df['FinCap_AutoDeposit_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_AutoDeposit_Checkin_2017Q2']=df['FinCap_AutoDeposit_Checkin_2017Q2'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit_Checkin_2017Q2_code']=np.where(df['FinCap_AutoDeposit_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_AutoDeposit 2017_Q1']=df['FinCap_AutoDeposit 2017_Q1'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit 2017_Q1_code']=np.where(df['FinCap_AutoDeposit 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['FinCap_AutoDeposit_Checkin_2018Q2']=df['FinCap_AutoDeposit_Checkin_2018Q2'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit_Checkin_2018Q2_code']=np.where(df['FinCap_AutoDeposit_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_AutoDeposit_Checkin_2018Q1']=df['FinCap_AutoDeposit_Checkin_2018Q1'].fillna('NULL')\n",
    "df['FinCap_AutoDeposit_Checkin_2018Q1_code']=np.where(df['FinCap_AutoDeposit_Checkin_2018Q1']=='NULL', 'NULL', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2016\n",
    "def get_FincapAutoDeposit_2016(df):\n",
    "    if df['FinCap_AutoDeposit_Checkin 2016_Q4_code']=='1':\n",
    "        return df['FinCap_AutoDeposit_Checkin 2016_Q4']\n",
    "    elif df['FinCap_AutoDeposit_Checkin 2016_Q3_code']=='2':\n",
    "        return df['FinCap_AutoDeposit_Checkin 2016_Q3']\n",
    "    elif df['FinCap_AutoDeposit 2016_Q2_code']=='3':\n",
    "        return df['FinCap_AutoDeposit 2016_Q2']\n",
    "    elif df['FinCap_AutoDeposit 2016_Q1_code']=='4':\n",
    "        return df['FinCap_AutoDeposit 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapAutoDeposit_merged_Y1'] = df.apply(get_FincapAutoDeposit_2016, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2017\n",
    "def get_FincapAutoDeposit_2017(df):\n",
    "    if df['FinCap_AutoDeposit_Checkin_2017Q4_code']=='1':\n",
    "        return df['FinCap_AutoDeposit_Checkin_2017Q4']\n",
    "    elif df['FinCap_AutoDeposit_Checkin_2017Q3_code']=='2':\n",
    "        return df['FinCap_AutoDeposit_Checkin_2017Q3']\n",
    "    elif df['FinCap_AutoDeposit_Checkin_2017Q2_code']=='3':\n",
    "        return df['FinCap_AutoDeposit_Checkin_2017Q2']\n",
    "    elif df['FinCap_AutoDeposit 2017_Q1_code']=='4':\n",
    "        return df['FinCap_AutoDeposit 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapAutoDeposit_merged_Y2'] = df.apply(get_FincapAutoDeposit_2017, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 2018\n",
    "def get_FincapAutoDeposit_2018(df):\n",
    "    if df['FinCap_AutoDeposit_Checkin_2018Q2_code']=='1':\n",
    "        return df['FinCap_AutoDeposit_Checkin_2018Q2']\n",
    "    elif df['FinCap_AutoDeposit_Checkin_2018Q1_code']=='2':\n",
    "        return df['FinCap_AutoDeposit_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['FincapAutoDeposit_merged_Y3'] = df.apply(get_FincapAutoDeposit_2018, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check FincapLateFee data\n",
    "df_FincapAutoDeposit = df[['FinCap_AutoDeposit 2016_Q1','FinCap_AutoDeposit 2016_Q2','FinCap_AutoDeposit_Checkin 2016_Q3','FinCap_AutoDeposit_Checkin 2016_Q4','FincapAutoDeposit_merged_Y1',\n",
    "                  'FinCap_AutoDeposit 2017_Q1','FinCap_AutoDeposit_Checkin_2017Q2','FinCap_AutoDeposit_Checkin_2017Q3','FinCap_AutoDeposit_Checkin_2017Q4','FincapAutoDeposit_merged_Y2',\n",
    "                  'FinCap_AutoDeposit_Checkin_2018Q1','FinCap_AutoDeposit_Checkin_2018Q2','FincapAutoDeposit_merged_Y3']]\n",
    "df_FincapAutoDeposit=df_FincapAutoDeposit.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FincapAutoDeposit.to_excel('FincapAutoDeposit_check_9.24.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinCap_EmergencyFund_Merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FinCap_EmergencyFund_Baseline',\n",
       " 'FinCap_EmergencyFund 2016_Q1',\n",
       " 'FinCap_EmergencyFund 2016_Q2',\n",
       " 'FinCap_EmergencyFund_Checkin 2016_Q3',\n",
       " 'FinCap_EmergencyFund_Checkin 2016_Q4',\n",
       " 'FinCap_EmergencYesFund 2017_Q1',\n",
       " 'FinCap_EmergencYesFund_Checkin_2017Q2',\n",
       " 'FinCap_EmergencYesFund_Checkin_2017Q3',\n",
       " 'FinCap_EmergencYesFund_Checkin_2017Q4',\n",
       " 'FinCap_EmergencYesFund_Checkin_2018Q1',\n",
       " 'FinCap_EmergencyFund_Checkin_2018Q2']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Emergenc' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly FinCap_EmergencyFund data\n",
    "#2016\n",
    "df['FinCap_EmergencyFund_Checkin 2016_Q4']=df['FinCap_EmergencyFund_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['FinCap_EmergencyFund_Checkin 2016_Q4_code']=np.where(df['FinCap_EmergencyFund_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_EmergencyFund_Checkin 2016_Q3']=df['FinCap_EmergencyFund_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['FinCap_EmergencyFund_Checkin 2016_Q3_code']=np.where(df['FinCap_EmergencyFund_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_EmergencyFund 2016_Q2']=df['FinCap_EmergencyFund 2016_Q2'].fillna('NULL')\n",
    "df['FinCap_EmergencyFund 2016_Q2_code']=np.where(df['FinCap_EmergencyFund 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_EmergencyFund 2016_Q1']=df['FinCap_EmergencyFund 2016_Q1'].fillna('NULL')\n",
    "df['FinCap_EmergencyFund 2016_Q1_code']=np.where(df['FinCap_EmergencyFund 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['FinCap_EmergencYesFund_Checkin_2017Q4']=df['FinCap_EmergencYesFund_Checkin_2017Q4'].fillna('NULL')\n",
    "df['FinCap_EmergencYesFund_Checkin_2017Q4_code']=np.where(df['FinCap_EmergencYesFund_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_EmergencYesFund_Checkin_2017Q3']=df['FinCap_EmergencYesFund_Checkin_2017Q3'].fillna('NULL')\n",
    "df['FinCap_EmergencYesFund_Checkin_2017Q3_code']=np.where(df['FinCap_EmergencYesFund_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_EmergencYesFund_Checkin_2017Q2']=df['FinCap_EmergencYesFund_Checkin_2017Q2'].fillna('NULL')\n",
    "df['FinCap_EmergencYesFund_Checkin_2017Q2_code']=np.where(df['FinCap_EmergencYesFund_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_EmergencYesFund 2017_Q1']=df['FinCap_EmergencYesFund 2017_Q1'].fillna('NULL')\n",
    "df['FinCap_EmergencYesFund 2017_Q1_code']=np.where(df['FinCap_EmergencYesFund 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['FinCap_EmergencyFund_Checkin_2018Q2']=df['FinCap_EmergencyFund_Checkin_2018Q2'].fillna('NULL')\n",
    "df['FinCap_EmergencyFund_Checkin_2018Q2_code']=np.where(df['FinCap_EmergencyFund_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_EmergencYesFund_Checkin_2018Q1']=df['FinCap_EmergencYesFund_Checkin_2018Q1'].fillna('NULL')\n",
    "df['FinCap_EmergencYesFund_Checkin_2018Q1_code']=np.where(df['FinCap_EmergencYesFund_Checkin_2018Q1']=='NULL', 'NULL', '2')\n",
    "\n",
    "#For 2016\n",
    "def get_EmergencyFund_2016(df):\n",
    "    if df['FinCap_EmergencyFund_Checkin 2016_Q4_code']=='1':\n",
    "        return df['FinCap_EmergencyFund_Checkin 2016_Q4']\n",
    "    elif df['FinCap_EmergencyFund_Checkin 2016_Q3_code']=='2':\n",
    "        return df['FinCap_EmergencyFund_Checkin 2016_Q3']\n",
    "    elif df['FinCap_EmergencyFund 2016_Q2_code']=='3':\n",
    "        return df['FinCap_EmergencyFund 2016_Q2']\n",
    "    elif df['FinCap_EmergencyFund 2016_Q1_code']=='4':\n",
    "        return df['FinCap_EmergencyFund 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapEmergencyFund_merged_Y1'] = df.apply(get_EmergencyFund_2016, axis = 1)\n",
    "\n",
    "#For 2017\n",
    "def get_EmergencyFund_2017(df):\n",
    "    if df['FinCap_EmergencYesFund_Checkin_2017Q4_code']=='1':\n",
    "        return df['FinCap_EmergencYesFund_Checkin_2017Q4']\n",
    "    elif df['FinCap_EmergencYesFund_Checkin_2017Q3_code']=='2':\n",
    "        return df['FinCap_EmergencYesFund_Checkin_2017Q3']\n",
    "    elif df['FinCap_EmergencYesFund_Checkin_2017Q2_code']=='3':\n",
    "        return df['FinCap_EmergencYesFund_Checkin_2017Q2']\n",
    "    elif df['FinCap_EmergencYesFund 2017_Q1_code']=='4':\n",
    "        return df['FinCap_EmergencYesFund 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapEmergencyFund_merged_Y2'] = df.apply(get_EmergencyFund_2017, axis = 1)\n",
    "\n",
    "#For 2018\n",
    "def get_EmergencyFund_2018(df):\n",
    "    if df['FinCap_EmergencyFund_Checkin_2018Q2_code']=='1':\n",
    "        return df['FinCap_EmergencyFund_Checkin_2018Q2']\n",
    "    elif df['FinCap_AutoDeposit_Checkin_2018Q1_code']=='2':\n",
    "        return df['FinCap_AutoDeposit_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['FincapEmergencyFund_merged_Y3'] = df.apply(get_EmergencyFund_2018, axis = 1)\n",
    "\n",
    "#check FincapLateFee data\n",
    "df_FincapEmergencyFund = df[['FinCap_EmergencyFund 2016_Q1','FinCap_EmergencyFund 2016_Q2','FinCap_EmergencyFund_Checkin 2016_Q3','FinCap_EmergencyFund_Checkin 2016_Q4','FincapEmergencyFund_merged_Y1',\n",
    "                  'FinCap_EmergencYesFund 2017_Q1','FinCap_EmergencYesFund_Checkin_2017Q2','FinCap_EmergencYesFund_Checkin_2017Q3','FinCap_EmergencYesFund_Checkin_2017Q4','FincapEmergencyFund_merged_Y2',\n",
    "                  'FinCap_EmergencyFund_Checkin_2018Q2','FinCap_AutoDeposit_Checkin_2018Q1','FincapEmergencyFund_merged_Y3']]\n",
    "df_FincapEmergencyFund=df_FincapEmergencyFund.replace('NULL',\"\")\n",
    "\n",
    "#df_FincapEmergencyFund.to_excel('FincapEmergencyFund_check_9.24.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinCap_Budget_Merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FinCap_Budget_Baseline',\n",
       " 'FinCap_Budget 2016_Q1',\n",
       " 'FinCap_Budget 2016_Q2',\n",
       " 'FinCap_Budget_Checkin 2016_Q3',\n",
       " 'FinCap_Budget_Checkin 2016_Q4',\n",
       " 'FinCap_Budget 2017_Q1',\n",
       " 'FinCap_Budget_Checkin_2017Q2',\n",
       " 'FinCap_Budget_Checkin_2017Q3',\n",
       " 'FinCap_Budget_Checkin_2017Q4',\n",
       " 'FinCap_Budget_Checkin_2018Q1',\n",
       " 'FinCap_Budget_Checkin_2018Q2']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Budget'in w ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly FinCap_EmergencyFund data\n",
    "#2016\n",
    "df['FinCap_Budget_Checkin 2016_Q4']=df['FinCap_Budget_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['FinCap_Budget_Checkin 2016_Q4_code']=np.where(df['FinCap_Budget_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_Budget_Checkin 2016_Q3']=df['FinCap_Budget_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['FinCap_Budget_Checkin 2016_Q3_code']=np.where(df['FinCap_Budget_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_Budget 2016_Q2']=df['FinCap_Budget 2016_Q2'].fillna('NULL')\n",
    "df['FinCap_Budget 2016_Q2_code']=np.where(df['FinCap_Budget 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_Budget 2016_Q1']=df['FinCap_Budget 2016_Q1'].fillna('NULL')\n",
    "df['FinCap_Budget 2016_Q1_code']=np.where(df['FinCap_Budget 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['FinCap_Budget_Checkin_2017Q4']=df['FinCap_Budget_Checkin_2017Q4'].fillna('NULL')\n",
    "df['FinCap_Budget_Checkin_2017Q4_code']=np.where(df['FinCap_Budget_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_Budget_Checkin_2017Q3']=df['FinCap_Budget_Checkin_2017Q3'].fillna('NULL')\n",
    "df['FinCap_Budget_Checkin_2017Q3_code']=np.where(df['FinCap_Budget_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_Budget_Checkin_2017Q2']=df['FinCap_Budget_Checkin_2017Q2'].fillna('NULL')\n",
    "df['FinCap_Budget_Checkin_2017Q2_code']=np.where(df['FinCap_Budget_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_Budget 2017_Q1']=df['FinCap_Budget 2017_Q1'].fillna('NULL')\n",
    "df['FinCap_Budget 2017_Q1_code']=np.where(df['FinCap_Budget 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['FinCap_Budget_Checkin_2018Q2']=df['FinCap_Budget_Checkin_2018Q2'].fillna('NULL')\n",
    "df['FinCap_Budget_Checkin_2018Q2_code']=np.where(df['FinCap_Budget_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_Budget_Checkin_2018Q1']=df['FinCap_Budget_Checkin_2018Q1'].fillna('NULL')\n",
    "df['FinCap_Budget_Checkin_2018Q1_code']=np.where(df['FinCap_Budget_Checkin_2018Q1']=='NULL', 'NULL', '2')\n",
    "\n",
    "#For 2016\n",
    "def get_Budget_2016(df):\n",
    "    if df['FinCap_Budget_Checkin 2016_Q4_code']=='1':\n",
    "        return df['FinCap_Budget_Checkin 2016_Q4']\n",
    "    elif df['FinCap_Budget_Checkin 2016_Q3_code']=='2':\n",
    "        return df['FinCap_Budget_Checkin 2016_Q3']\n",
    "    elif df['FinCap_Budget 2016_Q2_code']=='3':\n",
    "        return df['FinCap_Budget 2016_Q2']\n",
    "    elif df['FinCap_Budget 2016_Q1_code']=='4':\n",
    "        return df['FinCap_Budget 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapBudget_merged_Y1'] = df.apply(get_Budget_2016, axis = 1)\n",
    "\n",
    "#For 2017\n",
    "def get_Budget_2017(df):\n",
    "    if df['FinCap_Budget_Checkin_2017Q4_code']=='1':\n",
    "        return df['FinCap_Budget_Checkin_2017Q4']\n",
    "    elif df['FinCap_Budget_Checkin_2017Q3_code']=='2':\n",
    "        return df['FinCap_Budget_Checkin_2017Q3']\n",
    "    elif df['FinCap_Budget_Checkin_2017Q2_code']=='3':\n",
    "        return df['FinCap_Budget_Checkin_2017Q2']\n",
    "    elif df['FinCap_Budget 2017_Q1_code']=='4':\n",
    "        return df['FinCap_Budget 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapBudget_merged_Y2'] = df.apply(get_Budget_2017, axis = 1)\n",
    "\n",
    "#For 2018\n",
    "def get_Budget_2018(df):\n",
    "    if df['FinCap_Budget_Checkin_2018Q2_code']=='1':\n",
    "        return df['FinCap_Budget_Checkin_2018Q2']\n",
    "    elif df['FinCap_Budget_Checkin_2018Q1_code']=='2':\n",
    "        return df['FinCap_Budget_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['FincapBudget_merged_Y3'] = df.apply(get_Budget_2018, axis = 1)\n",
    "\n",
    "#check FincapLateFee data\n",
    "df_FincapBudget = df[['FinCap_Budget 2016_Q1','FinCap_Budget 2016_Q2','FinCap_Budget_Checkin 2016_Q3','FinCap_Budget_Checkin 2016_Q4','FincapBudget_merged_Y1',\n",
    "                  'FinCap_Budget 2017_Q1','FinCap_Budget_Checkin_2017Q2','FinCap_Budget_Checkin_2017Q3','FinCap_Budget_Checkin_2017Q4','FincapBudget_merged_Y2',\n",
    "                  'FinCap_Budget_Checkin_2018Q1','FinCap_Budget_Checkin_2018Q2','FincapBudget_merged_Y3']]\n",
    "df_FincapBudget=df_FincapBudget.replace('NULL',\"\")\n",
    "\n",
    "#df_FincapBudget.to_excel('FincapBudget_check_9.25.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinCap_Goals_Merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fincap_Goals_Baseline',\n",
       " 'FinCap_Goals 2016_Q1',\n",
       " 'FinCap_Goals 2016_Q2',\n",
       " 'Fincap_Goals_Checkin 2016_Q3',\n",
       " 'FinCap_Goals_Checkin 2016_Q4',\n",
       " 'FinCap_Goals 2017_Q1',\n",
       " 'FinCap_Goals_Checkin_2017Q2',\n",
       " 'FinCap_Goals_Checkin_2017Q3',\n",
       " 'FinCap_Goals_Checkin_2017Q4',\n",
       " 'FinCap_Goals_Checkin_2018Q1',\n",
       " 'FinCap_Goals_Checkin_2018Q2']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Goals' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code quarterly FinCap_Goals data\n",
    "#2016\n",
    "df['FinCap_Goals_Checkin 2016_Q4']=df['FinCap_Goals_Checkin 2016_Q4'].fillna('NULL')\n",
    "df['FinCap_Goals_Checkin 2016_Q4_code']=np.where(df['FinCap_Goals_Checkin 2016_Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['Fincap_Goals_Checkin 2016_Q3']=df['Fincap_Goals_Checkin 2016_Q3'].fillna('NULL')\n",
    "df['Fincap_Goals_Checkin 2016_Q3_code']=np.where(df['Fincap_Goals_Checkin 2016_Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_Goals 2016_Q2']=df['FinCap_Goals 2016_Q2'].fillna('NULL')\n",
    "df['FinCap_Goals 2016_Q2_code']=np.where(df['FinCap_Goals 2016_Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_Goals 2016_Q1']=df['FinCap_Goals 2016_Q1'].fillna('NULL')\n",
    "df['FinCap_Goals 2016_Q1_code']=np.where(df['FinCap_Goals 2016_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2017\n",
    "df['FinCap_Goals_Checkin_2017Q4']=df['FinCap_Goals_Checkin_2017Q4'].fillna('NULL')\n",
    "df['FinCap_Goals_Checkin_2017Q4_code']=np.where(df['FinCap_Goals_Checkin_2017Q4']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_Goals_Checkin_2017Q3']=df['FinCap_Goals_Checkin_2017Q3'].fillna('NULL')\n",
    "df['FinCap_Goals_Checkin_2017Q3_code']=np.where(df['FinCap_Goals_Checkin_2017Q3']=='NULL', 'NULL', '2')\n",
    "\n",
    "df['FinCap_Goals_Checkin_2017Q2']=df['FinCap_Goals_Checkin_2017Q2'].fillna('NULL')\n",
    "df['FinCap_Goals_Checkin_2017Q2_code']=np.where(df['FinCap_Goals_Checkin_2017Q2']=='NULL', 'NULL', '3')\n",
    "\n",
    "df['FinCap_Goals 2017_Q1']=df['FinCap_Goals 2017_Q1'].fillna('NULL')\n",
    "df['FinCap_Goals 2017_Q1_code']=np.where(df['FinCap_Goals 2017_Q1']=='NULL', 'NULL', '4')\n",
    "\n",
    "#2018\n",
    "df['FinCap_Goals_Checkin_2018Q2']=df['FinCap_Goals_Checkin_2018Q2'].fillna('NULL')\n",
    "df['FinCap_Goals_Checkin_2018Q2_code']=np.where(df['FinCap_Goals_Checkin_2018Q2']=='NULL', 'NULL', '1')\n",
    "\n",
    "df['FinCap_Goals_Checkin_2018Q1']=df['FinCap_Goals_Checkin_2018Q1'].fillna('NULL')\n",
    "df['FinCap_Goals_Checkin_2018Q1_code']=np.where(df['FinCap_Goals_Checkin_2018Q1']=='NULL', 'NULL', '2')\n",
    "\n",
    "#For 2016\n",
    "def get_Goals_2016(df):\n",
    "    if df['FinCap_Goals_Checkin 2016_Q4_code']=='1':\n",
    "        return df['FinCap_Goals_Checkin 2016_Q4']\n",
    "    elif df['Fincap_Goals_Checkin 2016_Q3_code']=='2':\n",
    "        return df['Fincap_Goals_Checkin 2016_Q3']\n",
    "    elif df['FinCap_Goals 2016_Q2_code']=='3':\n",
    "        return df['FinCap_Goals 2016_Q2']\n",
    "    elif df['FinCap_Goals 2016_Q1_code']=='4':\n",
    "        return df['FinCap_Goals 2016_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapGoals_merged_Y1'] = df.apply(get_Goals_2016, axis = 1)\n",
    "\n",
    "#For 2017\n",
    "def get_Goals_2017(df):\n",
    "    if df['FinCap_Goals_Checkin_2017Q4_code']=='1':\n",
    "        return df['FinCap_Goals_Checkin_2017Q4']\n",
    "    elif df['FinCap_Goals_Checkin_2017Q3_code']=='2':\n",
    "        return df['FinCap_Goals_Checkin_2017Q3']\n",
    "    elif df['FinCap_Goals_Checkin_2017Q2_code']=='3':\n",
    "        return df['FinCap_Goals_Checkin_2017Q2']\n",
    "    elif df['FinCap_Goals 2017_Q1_code']=='4':\n",
    "        return df['FinCap_Goals 2017_Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "\n",
    "df['FincapGoals_merged_Y2'] = df.apply(get_Goals_2017, axis = 1)\n",
    "\n",
    "#For 2018\n",
    "def get_Goals_2018(df):\n",
    "    if df['FinCap_Goals_Checkin_2018Q2_code']=='1':\n",
    "        return df['FinCap_Goals_Checkin_2018Q2']\n",
    "    elif df['FinCap_Goals_Checkin_2018Q1_code']=='2':\n",
    "        return df['FinCap_Goals_Checkin_2018Q1']\n",
    "    else:\n",
    "        return \"NULL\"\n",
    "    \n",
    "df['FincapGoals_merged_Y3'] = df.apply(get_Goals_2018, axis = 1)\n",
    "\n",
    "#check FincapLateFee data\n",
    "df_FincapGoals = df[['FinCap_Goals 2016_Q1','FinCap_Goals 2016_Q2','Fincap_Goals_Checkin 2016_Q3','FinCap_Goals_Checkin 2016_Q4','FincapGoals_merged_Y1',\n",
    "                  'FinCap_Goals 2017_Q1','FinCap_Goals_Checkin_2017Q2','FinCap_Goals_Checkin_2017Q3','FinCap_Goals_Checkin_2017Q4','FincapGoals_merged_Y2',\n",
    "                  'FinCap_Goals_Checkin_2018Q1','FinCap_Goals_Checkin_2018Q2','FincapGoals_merged_Y3']]\n",
    "df_FincapGoals=df_FincapGoals.replace('NULL',\"\")\n",
    "\n",
    "#df_FincapGoals.to_excel('FincapGoals_check_9.25.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinCap_Goals_Checkin_2018Q1 contains value 0--which should not be in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FinCap_LateFee_IsBlank',\n",
       " 'FinCap_IncomeExpenses_IsBlank',\n",
       " 'FinCap_AutoDeposit_IsBlank',\n",
       " 'FinCap_EmergencyFund_IsBlank',\n",
       " 'FinCap_Budget_IsBlank',\n",
       " 'FinCap_Goals_IsBlank',\n",
       " 'Savings_Blank',\n",
       " 'CreditScore_Blank',\n",
       " 'Debt_Blank',\n",
       " 'Wage_Blank',\n",
       " 'Income_Blank',\n",
       " 'Savings_Blank2',\n",
       " 'CreditScore_Blank2',\n",
       " 'Debt_Blank2',\n",
       " 'Wage_Blank2',\n",
       " 'Income_Blank2',\n",
       " 'FinCap_Budget_IsBlank2',\n",
       " 'FinCap_Goals_IsBlank2',\n",
       " 'FinCap_AutoDeposit_IsBlank2',\n",
       " 'FinCap_IncomeExpenses_IsBlank2',\n",
       " 'FinCap_LateFee_IsBlank2',\n",
       " 'Savings_IsBlank_Y1',\n",
       " 'CreditScore_IsBlank_Y1',\n",
       " 'Debt_IsBlank_Y1',\n",
       " 'Wage_IsBlank_Y1',\n",
       " 'IncomeHH_IsBlank_Y1',\n",
       " 'FinCap_Budget_IsBlankYear1',\n",
       " 'Fincap_Goals_IsBlankYear1',\n",
       " 'FinCap_EmergencyFund_IsBlankYear1',\n",
       " 'FinCap_AutoDeposit_IsBlankYear1',\n",
       " 'FinCap_IncomeExpenses_IsBlankYear1',\n",
       " 'FinCap_LateFee_IsBlankYear1']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df_overlap.columns if 'Blank' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Savings_merged_Y1', 'Savings_merged_Y2', 'Savings_merged_Y3']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Savings_merged' in w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add isblank columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savings_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Savings_Isblank_Y1']=np.where(df['Savings_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['Savings_Isblank_Y2']=np.where(df['Savings_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['Savings_Isblank_Y3']=np.where(df['Savings_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CreditScore_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore_merged_Y1', 'CreditScore_merged_Y2', 'CreditScore_merged_Y3']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'CreditScore_m' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CreditScore_Isblank_Y1']=np.where(df['CreditScore_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['CreditScore_Isblank_Y2']=np.where(df['CreditScore_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['CreditScore_Isblank_Y3']=np.where(df['CreditScore_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debt_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Debt_merged_Y1', 'Debt_merged_Y2', 'Debt_merged_Y3']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Debt_m' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Debt_Isblank_Y1']=np.where(df['Debt_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['Debt_Isblank_Y2']=np.where(df['Debt_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['Debt_Isblank_Y3']=np.where(df['Debt_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wage_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wages1_merged_Y1', 'Wages1_merged_Y2', 'Wages1_merged_Y3']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Wages1_m' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Wages1_Isblank_Y1']=np.where(df['Wages1_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['Wages1_Isblank_Y2']=np.where(df['Wages1_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['Wages1_Isblank_Y3']=np.where(df['Wages1_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IncomeHH_merged_Y1', 'IncomeHH_merged_Y2', 'IncomeHH_merged_Y3']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'IncomeHH_m' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IncomeHH_Isblank_Y1']=np.where(df['IncomeHH_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['IncomeHH_Isblank_Y2']=np.where(df['IncomeHH_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['IncomeHH_Isblank_Y3']=np.where(df['IncomeHH_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fincap_LateFee_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FincapLateFee_merged_Y1',\n",
       " 'FincapLateFee_merged_Y2',\n",
       " 'FincapLateFee_merged_Y3']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'FincapLateFee_merged' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FincapLateFee_Isblank_Y1']=np.where(df['FincapLateFee_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapLateFee_Isblank_Y2']=np.where(df['FincapLateFee_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapLateFee_Isblank_Y3']=np.where(df['FincapLateFee_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinCap_IncomeExpenses_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FincapIncomeExpenses_merged_Y1',\n",
       " 'FincapIncomeExpenses_merged_Y2',\n",
       " 'FincapIncomeExpenses_merged_Y3']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'FincapIncomeExpenses_merged' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FincapIncomeExpenses_Isblank_Y1']=np.where(df['FincapIncomeExpenses_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapIncomeExpenses_Isblank_Y2']=np.where(df['FincapIncomeExpenses_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapIncomeExpenses_Isblank_Y3']=np.where(df['FincapIncomeExpenses_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinCap_AutoDeposit_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FincapAutoDeposit_merged_Y1',\n",
       " 'FincapAutoDeposit_merged_Y2',\n",
       " 'FincapAutoDeposit_merged_Y3']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'FincapAutoDeposit_merged' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FincapAutoDeposit_Isblank_Y1']=np.where(df['FincapAutoDeposit_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapAutoDeposit_Isblank_Y2']=np.where(df['FincapAutoDeposit_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapAutoDeposit_Isblank_Y3']=np.where(df['FincapAutoDeposit_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FincapEmergencyFund_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FincapEmergencyFund_merged_Y1',\n",
       " 'FincapEmergencyFund_merged_Y2',\n",
       " 'FincapEmergencyFund_merged_Y3']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'FincapEmergencyFund_merged' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FincapEmergencyFund_Isblank_Y1']=np.where(df['FincapEmergencyFund_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapEmergencyFund_Isblank_Y2']=np.where(df['FincapEmergencyFund_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapEmergencyFund_Isblank_Y3']=np.where(df['FincapEmergencyFund_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FincapBudget_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FincapBudget_merged_Y1', 'FincapBudget_merged_Y2', 'FincapBudget_merged_Y3']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'FincapBudget_merged' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FincapBudget_Isblank_Y1']=np.where(df['FincapBudget_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapBudget_Isblank_Y2']=np.where(df['FincapBudget_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapBudget_Isblank_Y3']=np.where(df['FincapBudget_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FincapGoals_Isblank_Y1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FincapGoals_merged_Y1', 'FincapGoals_merged_Y2', 'FincapGoals_merged_Y3']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'FincapGoals_merged' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FincapGoals_Isblank_Y1']=np.where(df['FincapGoals_merged_Y1']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapGoals_Isblank_Y2']=np.where(df['FincapGoals_merged_Y2']=='NULL', 'Blank', 'Not Blank')\n",
    "df['FincapGoals_Isblank_Y3']=np.where(df['FincapGoals_merged_Y3']=='NULL', 'Blank', 'Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop _code columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [w for w in df.columns if '_code' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel('Overlap2018_10.2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Savings_merged_Y1'].to_excel('Savings_9.24.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/48527420/if-elseif-else-condition-in-pandas-dataframe-list-comprehension\n",
    "#index\n",
    "#https://stackoverflow.com/questions/48382122/pandas-dataframe-check-if-index-exists-in-a-multi-index\n",
    "#can research if function in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out clients have at least one check in data for three years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(r\"C:\\Users\\Leah\\Google Drive\\Parent Folder\\2. Clients\\Local\\Dallas\\Communities Foundation of Texas\\Q22018\\Data Work\\ForOverlapAnalysis\\Overlap2018_10.2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no_checkin_3years = df1[(df1['HasCheckinYear1'] == 'No') & (df1['HasCheckinYear2'] == 'No') & (df1['HasCheckinYear3'] == 'No')]\n",
    "\n",
    "#df_no_checkin_3years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.isin(df_no_checkin_3years)['ClientID_Baseline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_filter = df1[~df1.isin(df_no_checkin_3years)].dropna(how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_filter.to_excel('overlap2018_filter.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding _Y123 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[w for w in df1.columns if 'Isblank' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions1 = [\n",
    "    (df1['Savings_Isblank_Y1']=='Blank') & (df1['Savings_Isblank_Y2']=='Blank')&(df1['Savings_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['Savings_Isblank_Y123'] = np.select(conditions1, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions2 = [\n",
    "    (df1['CreditScore_Isblank_Y1']=='Blank') & (df1['CreditScore_Isblank_Y2']=='Blank')&(df1['CreditScore_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['CreditScore_Isblank_Y123'] = np.select(conditions2, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions3 = [\n",
    "    (df1['Debt_Isblank_Y1']=='Blank') & (df1['Debt_Isblank_Y2']=='Blank')&(df1['Debt_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['Debt_Isblank_Y123'] = np.select(conditions3, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions4 = [\n",
    "    (df1['Wages1_Isblank_Y1']=='Blank') & (df1['Wages1_Isblank_Y2']=='Blank')&(df1['Wages1_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['Wages1_Isblank_Y123'] = np.select(conditions4, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions5 = [\n",
    "    (df1['IncomeHH_Isblank_Y1']=='Blank') & (df1['IncomeHH_Isblank_Y2']=='Blank')&(df1['IncomeHH_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['IncomeHH_Isblank_Y123'] = np.select(conditions5, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions6 = [\n",
    "    (df1['FincapLateFee_Isblank_Y1']=='Blank') & (df1['FincapLateFee_Isblank_Y2']=='Blank')&(df1['FincapLateFee_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['FincapLateFee_Isblank_Y123'] = np.select(conditions6, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions7 = [\n",
    "    (df1['FincapIncomeExpenses_Isblank_Y1']=='Blank') & (df1['FincapIncomeExpenses_Isblank_Y2']=='Blank')&(df1['FincapIncomeExpenses_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['FincapIncomeExpenses_Isblank_Y123'] = np.select(conditions7, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions8 = [\n",
    "    (df1['FincapAutoDeposit_Isblank_Y1']=='Blank') & (df1['FincapAutoDeposit_Isblank_Y2']=='Blank')&(df1['FincapAutoDeposit_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['FincapAutoDeposit_Isblank_Y123'] = np.select(conditions8, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions9 = [\n",
    "    (df1['FincapEmergencyFund_Isblank_Y1']=='Blank') & (df1['FincapEmergencyFund_Isblank_Y2']=='Blank')&(df1['FincapEmergencyFund_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['FincapEmergencyFund_Isblank_Y123'] = np.select(conditions9, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions10 = [\n",
    "    (df1['FincapBudget_Isblank_Y1']=='Blank') & (df1['FincapBudget_Isblank_Y2']=='Blank')&(df1['FincapBudget_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['FincapBudget_Isblank_Y123'] = np.select(conditions10, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions11 = [\n",
    "    (df1['FincapGoals_Isblank_Y1']=='Blank') & (df1['FincapGoals_Isblank_Y2']=='Blank')&(df1['FincapGoals_Isblank_Y3']=='Blank')\n",
    "]\n",
    "choices1 = ['Blank']\n",
    "df1['FincapGoals_Isblank_Y123'] = np.select(conditions11, choices1, default='Not Blank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.replace('NULL',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel('overlap_includingBothData1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows that are not in other dataframe\n",
    "#https://stackoverflow.com/questions/28901683/pandas-get-rows-which-are-not-in-other-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employment Support    --AccessEmployment\n",
    "## Financial Coaching     --AccessFinancialCoach\n",
    "## Income Support      --AccessIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AccessEmployment_Baseline',\n",
       " 'AccessEmployment 2016_Q1',\n",
       " 'AccessEmployment 2016_Q2',\n",
       " 'AccessEmployment_Checkin 2016_Q3',\n",
       " 'AccessEmployment_Checkin 2016_Q4',\n",
       " 'AccessEmployment_Checkin 2016_Q4.1',\n",
       " 'AccessEmployment 2017_Q1',\n",
       " 'AccessEmployment BS 2017_Q1',\n",
       " 'AccessEmployment_Checkin_2017Q2',\n",
       " 'AccessEmployment_Checkin_2017Q3',\n",
       " 'AccessEmployment_Checkin_2017Q4',\n",
       " 'AccessEmployment_Checkin_2018Q1',\n",
       " 'AccessEmployment_Checkin_2018Q2',\n",
       " 'AccessEmployment_All Time2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'AccessEmployment' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AccessFinancialCoach_Baseline',\n",
       " 'AccessFinancialCoach 2016_Q1',\n",
       " 'AccessFinancialCoach 2016_Q2',\n",
       " 'AccessFinancialCoach_Checkin 2016_Q3',\n",
       " 'AccessFinancialCoach_Checkin 2016_Q4',\n",
       " 'AccessFinancialCoach_Checkin 2016_Q4.1',\n",
       " 'AccessFinancialCoach 2017_Q1',\n",
       " 'AccessFinancialCoach BS 2017_Q1',\n",
       " 'AccessFinancialCoach_Checkin_2017Q2',\n",
       " 'AccessFinancialCoach_Checkin_2017Q3',\n",
       " 'AccessFinancialCoach_Checkin_2017Q4',\n",
       " 'AccessFinancialCoach_Checkin_2018Q1',\n",
       " 'AccessFinancialCoach_Checkin_2018Q2',\n",
       " 'AccessFinancialCoach_All Time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'AccessFinancialCoach' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Access Income 2018 Q2 Checkin']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in df.columns if 'Access Income' in w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### need to recode AccessIncome for 2016Q2, 2016Q3, 2017Q1, 2018Q2--Access Income 2018 Q2 Checkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
